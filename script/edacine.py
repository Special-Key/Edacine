import os
import matplotlib.pyplot as plt
from pathlib import Path
import pandas as pd
import numpy as np
import seaborn as sns

# Ruta relativa desde scrpt/ hasta imagenes/
carpeta_imgs = Path("../imagenes")
carpeta_imgs.mkdir(parents=True, exist_ok=True)

# Contador para nombres √∫nicos
contador_graficos = {}

# Funci√≥n para guardar los gr√°ficos autom√°ticamente
def guardar_grafico():
    titulo = plt.gca().get_title()
    if not titulo:
        titulo = "grafico"
    nombre_base = "".join(c for c in titulo if c.isalnum() or c in (" ", "_")).strip().replace(" ", "_")
    if not nombre_base:
        nombre_base = "grafico"
    if nombre_base not in contador_graficos:
        contador_graficos[nombre_base] = 1
    else:
        contador_graficos[nombre_base] += 1
    numero = contador_graficos[nombre_base]
    nombre_archivo = f"{nombre_base}_{numero:02d}.jpg"
    ruta_guardado = carpeta_imgs / nombre_archivo
    plt.savefig(ruta_guardado, format="jpg", dpi=300, bbox_inches="tight")
    plt.close()
    print(f"‚úÖ Imagen guardada: {ruta_guardado}")






# HIP√ìTESIS 1 


# Leemos el archivo CSV y lo guardamos en una variable llamada "df"
movies_5000_df = pd.read_csv("../dataF/tmdb_5000_movies.csv")

# Mostramos las primeras 5 filas para ver c√≥mo es el contenido
movies_5000_df.head()

movies_5000_df.info()

# Leemos el archivo CSV y lo guardamos en una variable llamada "df"
movies_details_df = pd.read_csv("../dataF/AllMoviesDetailsCleaned.csv", sep=";")

# Mostramos las primeras 5 filas para ver c√≥mo es el contenido
movies_details_df.head()

movies_details_df.info()


# Filtramos las filas donde el presupuesto (budget) y la recaudaci√≥n (revenue) sean mayores que 0
dataframe_sin_ceros = movies_5000_df[(movies_5000_df['budget'] > 0) & (movies_5000_df['revenue'] > 0)]

# Mostramos cu√°ntas pel√≠culas quedan despu√©s del filtrado
print("N√∫mero de pel√≠culas despu√©s de filtrar:", len(dataframe_sin_ceros))


# Creamos el nuevo DataFrame solo con las columnas que nos interesan
presupuesto_recaudacion_df = dataframe_sin_ceros[['budget', 'revenue']]

# Renombramos las columnas al espa√±ol
presupuesto_recaudacion_df = presupuesto_recaudacion_df.rename(columns={
    'budget': 'presupuesto',
    'revenue': 'recaudacion'
})

# Mostramos las primeras filas para comprobar los cambios
print(presupuesto_recaudacion_df.head())

# Mostramos el n√∫mero de registros en el nuevo DataFrame
print("N√∫mero de pel√≠culas con presupuesto y recaudaci√≥n v√°lidos:", len(presupuesto_recaudacion_df))


# Creamos el gr√°fico de dispersi√≥n
plt.scatter(presupuesto_recaudacion_df['presupuesto'], presupuesto_recaudacion_df['recaudacion'])

# A√±adimos t√≠tulo y etiquetas a los ejes
plt.title("Relaci√≥n entre presupuesto y recaudaci√≥n")
plt.xlabel("Presupuesto (en d√≥lares)")
plt.ylabel("Recaudaci√≥n (en d√≥lares)")

# Guardamos el gr√°fico

guardar_grafico()



# Creamos el gr√°fico de dispersi√≥n sin modificar el DataFrame original
plt.scatter(
    presupuesto_recaudacion_df['presupuesto'] / 1_000_000,  # Convertimos a millones solo para el gr√°fico
    presupuesto_recaudacion_df['recaudacion'] / 1_000_000   # Convertimos a millones solo para el gr√°fico
)

# A√±adimos t√≠tulo y etiquetas con unidades claras
plt.title("Relaci√≥n entre presupuesto y recaudaci√≥n (en millones)")
plt.xlabel("Presupuesto (millones de d√≥lares)")
plt.ylabel("Recaudaci√≥n (millones de d√≥lares)")

# Guardamos el gr√°fico

guardar_grafico()



# Mostramos los valores m√≠nimo y m√°ximo del presupuesto y la recaudaci√≥n
presupuesto_min = presupuesto_recaudacion_df['presupuesto'].min()
presupuesto_max = presupuesto_recaudacion_df['presupuesto'].max()
recaudacion_min = presupuesto_recaudacion_df['recaudacion'].min()
recaudacion_max = presupuesto_recaudacion_df['recaudacion'].max()

print(f"Presupuesto m√≠nimo: {presupuesto_min:,} $")
print(f"Presupuesto m√°ximo: {presupuesto_max:,} $")
print(f"Recaudaci√≥n m√≠nima: {recaudacion_min:,} $")
print(f"Recaudaci√≥n m√°xima: {recaudacion_max:,} $")


# Pel√≠cula con el presupuesto m√≠nimo
pelicula_presupuesto_min = dataframe_sin_ceros[dataframe_sin_ceros['budget'] == dataframe_sin_ceros['budget'].min()]
print("üé¨ Pel√≠cula con el presupuesto m√≠nimo:")
print(pelicula_presupuesto_min[['title', 'budget', 'revenue']])

# Pel√≠cula con el presupuesto m√°ximo
pelicula_presupuesto_max = dataframe_sin_ceros[dataframe_sin_ceros['budget'] == dataframe_sin_ceros['budget'].max()]
print("\nüé¨ Pel√≠cula con el presupuesto m√°ximo:")
print(pelicula_presupuesto_max[['title', 'budget', 'revenue']])

# Pel√≠cula con la recaudaci√≥n m√≠nima
pelicula_recaudacion_min = dataframe_sin_ceros[dataframe_sin_ceros['revenue'] == dataframe_sin_ceros['revenue'].min()]
print("\nüí∏ Pel√≠cula con la recaudaci√≥n m√≠nima:")
print(pelicula_recaudacion_min[['title', 'budget', 'revenue']])

# Pel√≠cula con la recaudaci√≥n m√°xima
pelicula_recaudacion_max = dataframe_sin_ceros[dataframe_sin_ceros['revenue'] == dataframe_sin_ceros['revenue'].max()]
print("\nüí∏ Pel√≠cula con la recaudaci√≥n m√°xima:")
print(pelicula_recaudacion_max[['title', 'budget', 'revenue']])


# Pel√≠culas con presupuesto menor de 1.000
presupuestos_bajos = dataframe_sin_ceros[dataframe_sin_ceros['budget'] < 1_000]
print("Pel√≠culas con presupuesto < 1.000:", len(presupuestos_bajos))

# Pel√≠culas con recaudaci√≥n menor de 1.000
recaudaciones_bajas = dataframe_sin_ceros[dataframe_sin_ceros['revenue'] < 1_000]
print("Pel√≠culas con recaudaci√≥n < 1.000:", len(recaudaciones_bajas))

# Pel√≠culas que cumplen cualquiera de las dos condiciones
total_sospechosas = dataframe_sin_ceros[
    (dataframe_sin_ceros['budget'] < 1_000) | (dataframe_sin_ceros['revenue'] < 1_000)
]
print("Total pel√≠culas con valores sospechosos:", len(total_sospechosas))


# Eliminamos las pel√≠culas con presupuesto o recaudaci√≥n sospechosamente bajos
dataframe_limpio = dataframe_sin_ceros[
    (dataframe_sin_ceros['budget'] >= 1_000) &
    (dataframe_sin_ceros['revenue'] >= 1_000)
]

# Mostramos cu√°ntas pel√≠culas quedan tras la limpieza
print("N√∫mero de pel√≠culas tras eliminar valores irreales:", len(dataframe_limpio))



# Dibujamos el gr√°fico usando los datos ya limpios y en millones de d√≥lares
plt.scatter(
    dataframe_limpio['budget'] / 1_000_000,
    dataframe_limpio['revenue'] / 1_000_000
)

# A√±adimos t√≠tulo y etiquetas con unidades
plt.title("Relaci√≥n entre presupuesto y recaudaci√≥n (datos limpios)")
plt.xlabel("Presupuesto (millones de d√≥lares)")
plt.ylabel("Recaudaci√≥n (millones de d√≥lares)")

# Guardamos el gr√°fico

guardar_grafico()




# Creamos un nuevo DataFrame temporal con valores en millones (sin modificar el original)
df_millones = dataframe_limpio.copy()
df_millones['presupuesto_millones'] = df_millones['budget'] / 1_000_000
df_millones['recaudacion_millones'] = df_millones['revenue'] / 1_000_000

# Creamos el gr√°fico con l√≠nea de regresi√≥n
plt.figure()
sns.regplot(
    x='presupuesto_millones',
    y='recaudacion_millones',
    data=df_millones,
    scatter_kws={'alpha': 0.4},  # puntos semitransparentes
    line_kws={'color': 'red'}    # l√≠nea roja
)

# Etiquetas y t√≠tulo
plt.title("Presupuesto vs Recaudaci√≥n con regresi√≥n lineal")
plt.xlabel("Presupuesto (millones de d√≥lares)")
plt.ylabel("Recaudaci√≥n (millones de d√≥lares)")
plt.tight_layout()

# Guardamos el gr√°fico

guardar_grafico()




# Copiamos el DataFrame limpio para no modificar el original
df_tramos = dataframe_limpio.copy()

# Creamos los tramos de presupuesto (en millones)
tramos = [0, 50_000_000, 100_000_000, 150_000_000, 200_000_000, 250_000_000, 300_000_000, 400_000_000]
nombres_tramos = ['0‚Äì50M', '50‚Äì100M', '100‚Äì150M', '150‚Äì200M', '200‚Äì250M', '250‚Äì300M', '300‚Äì400M']

# Creamos una nueva columna llamada 'grupo_presupuesto' con esos tramos
df_tramos['grupo_presupuesto'] = pd.cut(df_tramos['budget'], bins=tramos, labels=nombres_tramos)

# Agrupamos por 'grupo_presupuesto' y calculamos la media de recaudaci√≥n
media_recaudacion_por_tramo = df_tramos.groupby('grupo_presupuesto')['revenue'].mean() / 1_000_000  # en millones

# Mostramos los resultados num√©ricos
print("Media de recaudaci√≥n por grupo de presupuesto (en millones):")
print(media_recaudacion_por_tramo)

# Dibujamos el gr√°fico
plt.figure(figsize=(8, 5))
media_recaudacion_por_tramo.plot(kind='bar', color='skyblue')

# A√±adimos etiquetas y t√≠tulo
plt.title("Media de recaudaci√≥n por rango de presupuesto")
plt.xlabel("Rango de presupuesto")
plt.ylabel("Media de recaudaci√≥n (millones de d√≥lares)")
plt.xticks(rotation=45)
plt.tight_layout()

# Guardamos el gr√°fico

guardar_grafico()




# Contamos cu√°ntas pel√≠culas hay en cada grupo de presupuesto
conteo_por_grupo = df_tramos['grupo_presupuesto'].value_counts().sort_index()
print("N√∫mero de pel√≠culas por grupo de presupuesto:")
print(conteo_por_grupo)


correlacion = dataframe_limpio['budget'].corr(dataframe_limpio['revenue'])
print(f"Coeficiente de correlaci√≥n: {correlacion:.2f}")


# Renombramos las columnas en espa√±ol para coherencia general
dataframe_limpio = dataframe_limpio.rename(columns={
    'budget': 'presupuesto',
    'revenue': 'recaudacion'
})


# Calculamos la matriz de correlaci√≥n
matriz_corr = dataframe_limpio[['presupuesto', 'recaudacion']].corr()

# Dibujamos el mapa de calor
sns.heatmap(matriz_corr, annot=True, cmap='coolwarm', vmin=0, vmax=1)
plt.title("Matriz de correlaci√≥n (presupuesto vs. recaudaci√≥n)")

guardar_grafico()




# HIP√ìTESIS 2  

# Leemos el archivo usando '\t' como separador (tabulador)
premios_df = pd.read_csv('../dataF/full_data.csv', sep='\t')

premios_df


# Mostramos informaci√≥n b√°sica sobre el contenido del archivo
premios_df.info()

# Cargamos el segundo dataset, el de las valoraciones en IMDb
tmdb_df= pd.read_csv('../dataF/tmdb_5000_movies.csv')
tmdb_df

# Mostramos la informaci√≥n b√°sica de este dataframe
tmdb_df.info()

# Creamos un nuevo DataFrame solo con las columnas que nos interesan del de premios
premios_reducido = premios_df[['Film', 'Year', 'Winner']].copy()

# Y hacemos lo mismo con el DataFrame de TMDB
tmdb_reducido = tmdb_df[['original_title', 'release_date', 'vote_average']].copy()

# Mostramos las primeras filas de cada uno para confirmar que se han creado correctamente
print("Premios (reducido):")
print(premios_reducido.head())

print("\nTMDB (reducido):")
print(tmdb_reducido.head())


# 1. Creamos una nueva columna con los t√≠tulos en min√∫sculas para comparar mejor
premios_reducido['titulo_normalizado'] = premios_reducido['Film'].str.lower()
tmdb_reducido['titulo_normalizado'] = tmdb_reducido['original_title'].str.lower()

# 2. Extraemos el A√ëO como n√∫mero (por si lo necesitamos para emparejar a√±os m√°s adelante)

# En premios_reducido, cogemos los 4 primeros caracteres de la columna 'Year' y los convertimos en n√∫mero
premios_reducido['anio_premio'] = premios_reducido['Year'].str[:4].astype('Int64')  # Soporta valores nulos

# En tmdb_reducido, cogemos los 4 primeros caracteres de la fecha de estreno
tmdb_reducido['anio_estreno'] = tmdb_reducido['release_date'].str[:4].astype('Int64')

# 3. Mostramos las primeras filas de cada uno para confirmar los cambios
#print("Premios reducido (con columnas nuevas):")
premios_reducido.head()

print("\nTMDB reducido (con columnas nuevas):")
tmdb_reducido.head()


print("Premios reducido (con columnas nuevas):")
premios_reducido.head()

# Hacemos el merge solo por el t√≠tulo normalizado
peliculas_comunes = pd.merge(
    premios_reducido,
    tmdb_reducido,
    how='inner',  # solo coincidencias
    on='titulo_normalizado',
    suffixes=('_premios', '_tmdb')
)

# Mostramos cu√°ntas coincidencias de pel√≠culas tenemos
print(f"\nN√∫mero total de pel√≠culas coincidentes (solo por t√≠tulo): {len(peliculas_comunes)}")
print()
# Mostramos las primeras filas del nuevo dataframe unido
print("Pel√≠culas con datos tanto de premios como de valoraciones:")
peliculas_comunes.head()


# Creamos una copia del DataFrame original para trabajar solo con lo necesario en esta hip√≥tesis
peliculas_hipotesis_1 = peliculas_comunes.copy()

# 1. Eliminamos las pel√≠culas sin valor en 'Winner'
peliculas_hipotesis_1 = peliculas_hipotesis_1.dropna(subset=['Winner'])

# 2. Convertimos 'Winner' a booleano
peliculas_hipotesis_1['Winner'] = peliculas_hipotesis_1['Winner'].astype(bool)

# 3. Eliminamos duplicados por t√≠tulo (nos quedamos solo con la primera aparici√≥n)
peliculas_hipotesis_1 = peliculas_hipotesis_1.drop_duplicates(subset='titulo_normalizado')

# Mostramos un resumen
print(peliculas_hipotesis_1[['Film', 'Winner', 'vote_average']].head())

# Mostramos cu√°ntas pel√≠culas finales tenemos
print(f"\nPel√≠culas preparadas para la hip√≥tesis 1 (sin duplicados ni nulos en 'Winner'): {len(peliculas_hipotesis_1)}")


# Separamos las pel√≠culas en dos grupos seg√∫n si ganaron o no
ganadoras = peliculas_hipotesis_1[peliculas_hipotesis_1['Winner'] == True]
no_ganadoras = peliculas_hipotesis_1[peliculas_hipotesis_1['Winner'] == False]

# Mostramos cu√°ntas hay en cada grupo
print(f"N√∫mero de pel√≠culas GANADORAS: {len(ganadoras)}")
print(f"N√∫mero de pel√≠culas NO ganadoras: {len(no_ganadoras)}")

# Estad√≠sticas descriptivas para cada grupo
print("\n--- Estad√≠sticas para GANADORAS ---")
print(ganadoras['vote_average'].describe())

print("\n--- Estad√≠sticas para NO GANADORAS ---")
print(no_ganadoras['vote_average'].describe())


# Cargamos el nuevo archivo que s√≠ contiene ganadoras y no ganadoras
oscars_df = pd.read_csv('../dataF/the_oscar_award.csv')

# Mostramos informaci√≥n general para ver columnas y tipos
oscars_df.info()

# Mostramos las primeras filas para ver ejemplos reales
oscars_df.head()


# Filtramos solo las filas que tienen nombre de pel√≠cula
oscars_df = oscars_df.dropna(subset=['film'])

# Mostramos cu√°ntas filas quedan despu√©s del filtrado
print(f"N√∫mero de filas con pel√≠cula v√°lida: {len(oscars_df)}")

# Mostramos un par de ejemplos
print(oscars_df[['film', 'winner']].head())


# Creamos una nueva columna con el t√≠tulo en min√∫sculas
oscars_df['titulo_normalizado'] = oscars_df['film'].str.lower()

# Mostramos solo 2 columnas de t√≠tulos para confirmar que se ha hecho bien
oscars_df[['film', 'titulo_normalizado']].head()


# Creamos el DataFrame reducido con solo las columnas necesarias
oscars_reducido = oscars_df[['film', 'winner', 'titulo_normalizado']].copy()

# Mostramos las primeras filas para comprobar que est√° bien
oscars_reducido.head()


# Unimos los dos DataFrames "oscars_reducido con tmdb_reducido" por el t√≠tulo normalizado
osc_tmdb_red_unidos_df = pd.merge(
    oscars_reducido,
    tmdb_reducido,
    how='inner',
    on='titulo_normalizado'
)

# Mostramos cu√°ntas pel√≠culas se han unido
print(f"N√∫mero de pel√≠culas unidas: {len(osc_tmdb_red_unidos_df)}")

# Mostramos algunas filas para comprobar el resultado
osc_tmdb_red_unidos_df[['film', 'winner', 'vote_average']].head()


# Creamos una copia limpia (Sin valores nulos ni duplicados por t√≠tulo) para trabajar sin
#  alterar el original
osc_tmdb_red_unidos_limpio_df = osc_tmdb_red_unidos_df.copy()

# Eliminamos filas sin nota del p√∫blico (por si hay alguna)
osc_tmdb_red_unidos_limpio_df = osc_tmdb_red_unidos_limpio_df.dropna(subset=['vote_average'])

# Eliminamos duplicados por t√≠tulo normalizado
osc_tmdb_red_unidos_limpio_df = osc_tmdb_red_unidos_limpio_df.drop_duplicates(subset='titulo_normalizado')

# Mostramos cu√°ntas pel√≠culas quedan para el an√°lisis final
print(f"N√∫mero de pel√≠culas listas para comparar: {len(osc_tmdb_red_unidos_limpio_df)}")

# Mostramos un ejemplo
print(osc_tmdb_red_unidos_limpio_df[['film', 'winner', 'vote_average']].head())


# Comparo valoraciones de ganadoras vs no ganadoras
# Separamos los dos grupos
ganadoras = osc_tmdb_red_unidos_limpio_df[osc_tmdb_red_unidos_limpio_df['winner'] == True]
no_ganadoras = osc_tmdb_red_unidos_limpio_df[osc_tmdb_red_unidos_limpio_df['winner'] == False]

# Mostramos cu√°ntas hay en cada grupo
print(f"N√∫mero de pel√≠culas GANADORAS: {len(ganadoras)}")
print(f"N√∫mero de pel√≠culas NO GANADORAS: {len(no_ganadoras)}")

# Estad√≠sticas descriptivas para cada grupo
print("\n--- Estad√≠sticas de valoraci√≥n (GANADORAS) ---")
print(ganadoras['vote_average'].describe())

print("\n--- Estad√≠sticas de valoraci√≥n (NO GANADORAS) ---")
print(no_ganadoras['vote_average'].describe())


# Creamos listas de valores para cada grupo
valores_ganadoras = osc_tmdb_red_unidos_limpio_df[osc_tmdb_red_unidos_limpio_df['winner'] == True]['vote_average']
valores_no_ganadoras = osc_tmdb_red_unidos_limpio_df[osc_tmdb_red_unidos_limpio_df['winner'] == False]['vote_average']

# Creamos el boxplot
plt.figure(figsize=(8, 6))
plt.boxplot([valores_ganadoras, valores_no_ganadoras], labels=['Ganadoras', 'No ganadoras'])

# A√±adimos etiquetas y t√≠tulo
plt.title('Comparaci√≥n de valoraciones IMDb\nGanadoras vs No ganadoras de premios')
plt.ylabel('Valoraci√≥n media (vote_average)')
plt.grid(True)

# Guardamos el gr√°fico

guardar_grafico()



from scipy.stats import ttest_ind

# ganadoras = osc_tmdb_red_unidos_limpio_df[osc_tmdb_red_unidos_limpio_df['winner'] == True]
# no_ganadoras = osc_tmdb_red_unidos_limpio_df[osc_tmdb_red_unidos_limpio_df['winner'] == False]

# Listas de notas para cada grupo
notas_ganadoras = ganadoras['vote_average']
notas_no_ganadoras = no_ganadoras['vote_average']

# Test t de diferencia de medias
resultado_ttest = ttest_ind(notas_ganadoras, notas_no_ganadoras)

# Mostramos el resultado
print(f"T-statistic: {resultado_ttest.statistic}")
print(f"P-valor: {resultado_ttest.pvalue}")



# HIP√ìTESIS 3

# Cargamos el data de TMDb
tmdb_df= pd.read_csv('../dataF/tmdb_5000_movies.csv')
tmdb_df

# Mostramos la informaci√≥n b√°sica de este dataframe
tmdb_df.info()

# Creamos un nuevo DataFrame solo con las columnas necesarias
tiempo_valoraci√≥n_df = tmdb_df[['runtime', 'vote_average']]

# Mostramos informaci√≥n b√°sica del nuevo DataFrame
tiempo_valoraci√≥n_df.info()


tiempo_valoraci√≥n_df

# 1. Eliminamos las 2 filas con runtime nulo
tiempo_valoraci√≥n_df = tiempo_valoraci√≥n_df.dropna(subset=['runtime'])

# 2. Eliminamos filas donde runtime sea igual a 0
tiempo_valoraci√≥n_df = tiempo_valoraci√≥n_df[tiempo_valoraci√≥n_df['runtime'] != 0]

# 3. Como sabemos que no hay NaN, eliminamos s√≥lo las filas donde vote_average sea igual a 0
tiempo_valoraci√≥n_df = tiempo_valoraci√≥n_df[tiempo_valoraci√≥n_df['vote_average'] != 0]

# Mostramos informaci√≥n b√°sica del nuevo DataFrame
tiempo_valoraci√≥n_df.info()


# Renombramos las columnas a espa√±ol
tiempo_valoraci√≥n_df = tiempo_valoraci√≥n_df.rename(columns={
    'runtime': 'duraci√≥n',
    'vote_average': 'valoraci√≥n_media'
})

tiempo_valoraci√≥n_df.head()


# Nueva funci√≥n para clasificar en 4 grupos
def clasificar_duraci√≥n(minutos):
    if minutos < 60:
        return 'Muy corta'
    elif 60 <= minutos < 90:
        return 'Corta'
    elif 90 <= minutos <= 120:
        return 'Media'
    else:
        return 'Larga'

# Aplicamos la funci√≥n al DataFrame
tiempo_valoraci√≥n_df['grupo_duraci√≥n'] = tiempo_valoraci√≥n_df['duraci√≥n'].apply(clasificar_duraci√≥n)

# Ver algunas filas para revisar que se asign√≥ correctamente
print(tiempo_valoraci√≥n_df[['duraci√≥n', 'grupo_duraci√≥n']].head(10))

# Contar cu√°ntas pel√≠culas hay por grupo
tiempo_valoraci√≥n_df['grupo_duraci√≥n'].value_counts()


# Creamos un nuevo DataFrame excluyendo el grupo 'Muy corta'
tiempo_valoraci√≥n_filtrado = tiempo_valoraci√≥n_df[tiempo_valoraci√≥n_df['grupo_duraci√≥n'] != 'Muy corta']

# Contamos cu√°ntas pel√≠culas hay en cada grupo despu√©s de eliminar 'Muy corta'
tiempo_valoraci√≥n_filtrado['grupo_duraci√≥n'].value_counts()


# Calculamos la valoraci√≥n media de cada grupo
medias_por_grupo = tiempo_valoraci√≥n_filtrado.groupby('grupo_duraci√≥n')['valoraci√≥n_media'].mean()

# Mostramos los resultados
print(medias_por_grupo)


# Ordenamos la serie de medias de menor a mayor
medias_ordenadas = medias_por_grupo.sort_values()
# Configuramos los datos para el gr√°fico
grupos = medias_ordenadas.index
valoraciones = medias_por_grupo.values

# Creamos la gr√°fica de barras
plt.figure(figsize=(8, 5))  # Tama√±o del gr√°fico
plt.bar(grupos, valoraciones)

# A√±adimos t√≠tulos y etiquetas
plt.title('Valoraci√≥n media por grupo de duraci√≥n')
plt.xlabel('Duraci√≥n por Grupo')
plt.ylabel('Valoraci√≥n media')

# Guardamos el gr√°fico

guardar_grafico()


# Colores en gradaci√≥n azul: m√°s claro para "Corta", m√°s oscuro para "Larga"
colores_azules = sns.color_palette("Blues", n_colors=3)

# Ordenamos las medias
medias_ordenadas = medias_por_grupo.sort_values()
grupos = medias_ordenadas.index
valoraciones = medias_ordenadas.values

# Creamos el gr√°fico
plt.figure(figsize=(8, 5))
barras = plt.bar(grupos, valoraciones, color=colores_azules)

# T√≠tulos y etiquetas
plt.title('Valoraci√≥n media por duraci√≥n')
plt.xlabel('Duraci√≥n', labelpad=15)
plt.ylabel('Valoraci√≥n media')

# Diccionario de etiquetas de duraci√≥n
duraciones = {
    'Corta': '60-89 min',
    'Media': '90-120 min',
    'Larga': '>120 min'
}

# Etiquetas de duraci√≥n encima de cada barra
for i, barra in enumerate(barras):
    altura = barra.get_height()
    grupo = grupos[i]
    texto = duraciones[grupo]
    plt.text(barra.get_x() + barra.get_width() / 2, altura + 0.1, texto,
             ha='center', fontsize=10)

# Guardamos el gr√°fico

guardar_grafico()


# Usamos 3 tonos progresivos de azul (del m√°s claro al m√°s oscuro)
colores_azules = sns.color_palette("Blues", n_colors=3)

# Creamos el boxplot con esa gradaci√≥n
plt.figure(figsize=(8, 5))
sns.boxplot(x='grupo_duraci√≥n', y='valoraci√≥n_media',
            data=tiempo_valoraci√≥n_filtrado,
            order=['Corta', 'Media', 'Larga'],
            palette=colores_azules)

# T√≠tulos y etiquetas
plt.title('Distribuci√≥n de valoraciones por duraci√≥n')
plt.xlabel('Duraci√≥n', labelpad=15)
plt.ylabel('Valoraci√≥n media')

# Guardamos el gr√°fico

guardar_grafico()


plt.figure(figsize=(8, 5))
sns.regplot(x='duraci√≥n', y='valoraci√≥n_media', data=tiempo_valoraci√≥n_df, scatter_kws={'alpha':0.5}, line_kws={"color": "red"})
plt.title('Tendencia entre duraci√≥n y valoraci√≥n')
plt.xlabel('Duraci√≥n (minutos)', labelpad=15)
plt.ylabel('Valoraci√≥n media')

# Guardamos el gr√°fico
guardar_grafico()



# HIP√ìTESIS 4

# Cargamos el data de TMDb
tmdb_df= pd.read_csv('../dataF/tmdb_5000_movies.csv')
tmdb_df.head(2)

# Mostramos la informaci√≥n b√°sica de este dataframe
tmdb_df.info()

# Importamos la librer√≠a json para poder convertir textos JSON en estructuras de Python
import json

# Funci√≥n para convertir el texto de la columna 'genres' en una lista de nombres de g√©neros
def extraer_nombres_generos(texto_generos):
    try:
        # Paso 1: Convertimos el texto JSON a una lista de diccionarios
        lista_diccionarios = json.loads(texto_generos)

        # Paso 2: Creamos una lista vac√≠a para guardar los nombres
        nombres_generos = []

        # Paso 3: Recorremos cada diccionario dentro de la lista
        for genero in lista_diccionarios:
            # Extraemos el valor del campo 'name' y lo a√±adimos a la lista
            nombres_generos.append(genero['name'])

        # Paso 4: Devolvemos la lista de nombres
        return nombres_generos

    except json.JSONDecodeError:
        # Si hay un error al convertir el texto, devolvemos una lista vac√≠a
        return []

# Aplicamos la funci√≥n a toda la columna 'genres' y creamos una nueva columna 'lista_generos'
tmdb_df['lista_generos'] = tmdb_df['genres'].apply(extraer_nombres_generos)

# Mostramos las primeras filas para comprobar que se ha creado correctamente la nueva columna
# para que te muestre 200 filas:
pd.set_option('display.max_rows', 200)

tmdb_df[['genres', 'lista_generos']].head()


# Creamos un conjunto vac√≠o para guardar los g√©neros √∫nicos (sin repeticiones)
generos_unicos = set()

# Recorremos cada fila de la columna 'lista_generos'
for lista in tmdb_df['lista_generos']:
    # Por si hay valores nulos o mal formateados
    if isinstance(lista, list):
        for genero in lista:
            generos_unicos.add(genero)

# Convertimos el conjunto en una lista ordenada alfab√©ticamente
generos_unicos = sorted(list(generos_unicos))

# Mostramos el n√∫mero total de g√©neros √∫nicos encontrados
print(f"Total de g√©neros √∫nicos: {len(generos_unicos)}")

# Mostramos la lista completa de g√©neros √∫nicos
for genero in generos_unicos:
    print(genero)


# Comprobamos cu√°ntas filas tienen 'lista_generos' vac√≠a o nula
faltan_generos = tmdb_df['lista_generos'].isnull().sum()
listas_vacias = tmdb_df['lista_generos'].apply(lambda x: isinstance(x, list) and len(x) == 0).sum()

print(f"Filas con valor nulo en 'lista_generos': {faltan_generos}")
print(f"Filas con lista vac√≠a en 'lista_generos': {listas_vacias}")



# Eliminamos las filas donde 'lista_generos' es una lista vac√≠a
tmdb_df = tmdb_df[tmdb_df['lista_generos'].apply(lambda x: len(x) > 0)]

# Comprobamos que ya no hay listas vac√≠as
print(tmdb_df['lista_generos'].apply(lambda x: len(x) == 0).sum())

# Mostramos el n√∫mero total de filas (pel√≠culas) en el DataFrame
print(f"N√∫mero total de pel√≠culas: {len(tmdb_df)}")


# Lista definitiva de g√©neros considerados SERIOS
generos_serios = [
    'Action', 'Crime', 'Documentary', 'Drama', 'Foreign', 'History',
    'Horror', 'Mystery', 'TV Movie', 'Thriller', 'War', 'Western', 'Religion'
]

# Funci√≥n que clasifica una pel√≠cula como 'seria' o 'ligera' seg√∫n el % de g√©neros serios
def clasificar_pelicula(lista_generos):
    contador_serios = 0

    for genero in lista_generos:
        if genero in generos_serios:
            contador_serios += 1

    porcentaje_serios = contador_serios / len(lista_generos)

    if porcentaje_serios > 0.5:
        return 'seria'
    else:
        return 'ligera'

# Aplicamos la funci√≥n al DataFrame
tmdb_df['tipo_pelicula'] = tmdb_df['lista_generos'].apply(clasificar_pelicula)

# Mostramos algunas filas para comprobar que se ha aplicado correctamente
tmdb_df[['lista_generos', 'tipo_pelicula']].head(15)


# Agrupamos el DataFrame por 'tipo_pelicula' y calculamos la media de 'vote_average'
medias_por_tipo = tmdb_df.groupby('tipo_pelicula')['vote_average'].mean()

# Mostramos el resultado
print("Media de valoraci√≥n (vote_average) por tipo de pel√≠cula:")
print(medias_por_tipo)



# Ajustamos el tama√±o de la figura
plt.figure(figsize=(8, 5))

# Creamos el boxplot con seaborn
sns.boxplot(
    data=tmdb_df,
    x='tipo_pelicula',        # Clasificaci√≥n: 'seria' o 'ligera'
    y='vote_average',         # Valoraci√≥n media
    palette='pastel'          # Colores suaves (opcional)
)

# A√±adimos t√≠tulo y etiquetas
plt.title('Distribuci√≥n de valoraciones por tipo de pel√≠cula (boxplot)')
plt.xlabel('Tipo de pel√≠cula')
plt.ylabel('Valoraci√≥n media (vote_average)')

# Guardamos el gr√°fico

guardar_grafico()


# Separamos las valoraciones seg√∫n el tipo de pel√≠cula para calcular la varianza
# para hacer el t-test de Student 
valoraciones_serias = tmdb_df[tmdb_df['tipo_pelicula'] == 'seria']['vote_average']
valoraciones_ligeras = tmdb_df[tmdb_df['tipo_pelicula'] == 'ligera']['vote_average']

# comprobamos si tienen varianzas distintas (para calcular el t-test de Student)
print("Varianza pel√≠culas serias:", valoraciones_serias.var())
print("Varianza pel√≠culas ligeras:", valoraciones_ligeras.var())



from scipy.stats import ttest_ind

# Separamos las valoraciones por tipo de pel√≠cula
valoraciones_serias = tmdb_df[tmdb_df['tipo_pelicula'] == 'seria']['vote_average']
valoraciones_ligeras = tmdb_df[tmdb_df['tipo_pelicula'] == 'ligera']['vote_average']

# Realizamos el test t para muestras independientes (varianzas diferentes)
t_stat, p_valor = ttest_ind(valoraciones_serias, valoraciones_ligeras, equal_var=False)

# Mostramos los resultados
print(f'Estad√≠stico t: {t_stat:.4f}')
print(f'Valor p: {p_valor:.4f}')


# HIP√ìTESIS 5

# Leemos el archivo con datos de casting
casting_df = pd.read_csv("../dataF/AllMoviesCastingRaw.csv", sep=";")

# Leemos el archivo de pel√≠culas y lo llamamos 'tmdb_df'
tmdb_df = pd.read_csv("../dataF/tmdb_5000_movies.csv")

# Mostramos la informaci√≥n del DataFrame de casting
print("üìÑ Informaci√≥n de 'casting_df':")
casting_df.info()

print("\n" + "-"*80 + "\n")

# Mostramos la informaci√≥n del DataFrame de pel√≠culas
print("üé¨ Informaci√≥n de 'tmdb_df':")
tmdb_df.info()


 #Vamos a comprobar si los id del tmdb_df tambi√©n aparecen en casting_df y si est√°n 
 # duplicados all√≠

# Contamos cu√°ntas veces aparece cada 'id' en casting_df
conteo_ids_casting = casting_df['id'].value_counts()

# Mostramos cu√°ntos ids tienen m√°s de una fila en casting_df
print("N√∫mero de ids duplicados en casting_df:", (conteo_ids_casting > 1).sum())

# Y cu√°ntos hay en total en tmdb_df
print("N√∫mero total de pel√≠culas en tmdb_df:", tmdb_df['id'].nunique())


# Extraemos solo la columna 'id' del DataFrame de casting
# As√≠ creamos una versi√≥n m√°s peque√±a que solo tiene los identificadores
casting_temp = casting_df[['id']]

# Extraemos del DataFrame tmdb_df las columnas 'id' y 'title'
# 'title' contiene el nombre de la pel√≠cula, que usaremos para comprobar si los ids coinciden con los t√≠tulos
tmdb_temp = tmdb_df[['id', 'title']]

# Hacemos una uni√≥n (merge) de los dos DataFrames por la columna 'id'
# 'inner' significa que solo se incluir√°n los ids que existan en ambos DataFrames
comparacion = pd.merge(casting_temp, tmdb_temp, on="id", how="inner")

# Mostramos las primeras 10 filas del resultado
# Esto nos permitir√° ver qu√© t√≠tulos hay para los ids que existen en ambos archivos
print(comparacion.head(10))


# Seleccionamos columnas de inter√©s del DataFrame de casting
# Para ver qu√© actores est√°n en cada id
casting_verificacion = casting_df[['id', 'actor1_name', 'actor2_name', 'actor3_name']]

# Hacemos un merge con tmdb_df para obtener el t√≠tulo de la pel√≠cula
verificacion_completa = pd.merge(casting_verificacion, tmdb_df[['id', 'title']], on='id', how='inner')

# Mostramos algunas filas
verificacion_completa.head(50)


# Paso 1: Extraemos las columnas que necesitamos de cada DataFrame
# Del DataFrame de casting nos quedamos con 'id' y 'actor_number'
casting_reducido = casting_df[['id', 'actor_number']]

# Del DataFrame tmdb_df nos quedamos con 'id', 'title' y 'vote_average'
tmdb_reducido = tmdb_df[['id', 'title', 'vote_average']]

# Paso 2: Unimos ambos DataFrames por 'id'
# Solo conservar√° las pel√≠culas que existan en los dos archivos
dfs_combinados = pd.merge(casting_reducido, tmdb_reducido, on='id', how='inner')

# Paso 3: Mostramos la informaci√≥n del nuevo DataFrame
print(" Informaci√≥n del nuevo DataFrame combinado:")
dfs_combinados.info()

# Paso 4: Mostramos las primeras filas para ver c√≥mo ha quedado
print("\n Primeras filas del nuevo DataFrame:")
dfs_combinados.head()


# Creamos una lista con los nombres de las columnas que queremos conservar
columnas_actores = ['id', 'actor1_name', 'actor2_name', 'actor3_name', 'actor4_name', 'actor5_name']

# Creamos una copia del DataFrame casting_df con solo esas columnas
actores_df = casting_df[columnas_actores].copy()

# Mostramos las primeras 25 filas del nuevo DataFrame para ver c√≥mo est√°n los datos
print("üé¨ Primeras 25 filas del DataFrame 'actores_df':")
actores_df.head(25)


# Vamos a reemplazar el texto 'none' por valores nulos (NaN) en las columnas de actores
# Esto nos permitir√° luego contar cu√°ntos actores reales tiene cada pel√≠cula

# Aplicamos esto solo a las columnas actor1_name a actor5_name (excluimos 'id')
columnas_nombres = ['actor1_name', 'actor2_name', 'actor3_name', 'actor4_name', 'actor5_name']

# Usamos un bucle para recorrer cada columna y hacer el reemplazo
for columna in columnas_nombres:
    actores_df[columna] = actores_df[columna].replace('none', pd.NA)

# Mostramos de nuevo las 25 primeras filas para comprobar que ya no aparece 'none'
print("Revisi√≥n despu√©s de reemplazar 'none' por NaN:")
actores_df.head(25)


# Paso 1: Seleccionamos solo las columnas que contienen los nombres de actores principales
columnas_nombres = ['actor1_name', 'actor2_name', 'actor3_name', 'actor4_name', 'actor5_name']

# Paso 2: Creamos una nueva columna que contar√° cu√°ntos de esos campos NO est√°n vac√≠os (no son NaN)
# .notna() devuelve True donde hay valor, y False donde hay vac√≠o
# .sum(axis=1) suma los True en cada fila (True cuenta como 1)
actores_df['n_act'] = actores_df[columnas_nombres].notna().sum(axis=1)

# Paso 3: Mostramos algunas filas para comprobar que la nueva columna se ha a√±adido correctamente
print("üìä Recuento de actores principales por pel√≠cula:")
actores_df.head(25)



# Paso 3: Unimos ambos DataFrames por la columna 'id'
dfs_unidos = pd.merge(actores_df, tmdb_reducido, on='id', how='inner')

# Paso 4: Mostramos informaci√≥n b√°sica del DataFrame final
print("‚ÑπÔ∏è Informaci√≥n del DataFrame 'dfs_unidos':")
dfs_unidos.info()

# Paso 5: Mostramos las primeras filas para comprobar que se ha unido bien
print("\nüìÑ Primeras 25 filas del DataFrame combinado:")
dfs_unidos.head(25)


# Definimos el nuevo orden de columnas
nuevo_orden_columnas = [
    'id', 'title',                      # Primero el identificador y el t√≠tulo
    'actor1_name', 'actor2_name',       # Luego los actores
    'actor3_name', 'actor4_name', 'actor5_name',
    'n_act',            # Despu√©s el n√∫mero de actores principales
    'vote_average'                      # Y por √∫ltimo la valoraci√≥n
]

# Reordenamos el DataFrame usando la lista anterior
dfs_unidos = dfs_unidos[nuevo_orden_columnas]

# Mostramos las primeras filas para comprobar que se ha hecho correctamente
print("‚úÖ Columnas reordenadas:")
dfs_unidos.head(5)


# Cambiamos el nombre de la columna 'vote_average' por 'vot_av'
dfs_unidos = dfs_unidos.rename(columns={'vote_average': 'vot_av'})

# Mostramos las primeras filas para confirmar el cambio
print("‚úÖ Cambio de nombre aplicado. Vista previa:")
dfs_unidos.head(5)



dfs_unidos.info()


# üé≠ Paso 1: Filtramos las pel√≠culas que tienen 0 actores principales
peliculas_sin_actores = dfs_unidos[dfs_unidos['n_act'] == 0]

# Mostramos cu√°ntas son
print(f"üé≠ N√∫mero de pel√≠culas sin actores principales: {len(peliculas_sin_actores)}")

# Mostramos las primeras filas para inspecci√≥n
peliculas_sin_actores.head(10)


# Paso 1: Filtramos las pel√≠culas con valoraci√≥n igual a 0
peliculas_con_valoracion_cero = dfs_unidos[dfs_unidos['vot_av'] == 0]

# Paso 2: Contamos cu√°ntas hay
cantidad_valoracion_cero = len(peliculas_con_valoracion_cero)
print(f"üéØ Pel√≠culas con valoraci√≥n 0: {cantidad_valoracion_cero}")

# Paso 3 (opcional): Vemos algunas de ellas para entender el tipo de pel√≠culas que son
print(peliculas_con_valoracion_cero[['title', 'vot_av']].head(10))


# Creamos un nuevo DataFrame filtrado: sin pel√≠culas con 0 actores ni votaci√≥n 0
dfs_limpio = dfs_unidos[(dfs_unidos['n_act'] > 0) & (dfs_unidos['vot_av'] > 0)]

# Mostramos cu√°ntas pel√≠culas quedan tras limpiar
print(f"‚úÖ Pel√≠culas disponibles para an√°lisis despu√©s de limpiar: {len(dfs_limpio)}")

# Mostramos una vista previa para confirmar que todo est√° en orden
dfs_limpio.head(10)


# 1Ô∏è‚É£ Total de pel√≠culas antes de la limpieza
total_original = len(dfs_unidos)
print(f"üé¨ Total original de pel√≠culas: {total_original}")

# 2Ô∏è‚É£ Cu√°ntas pel√≠culas tienen 0 actores
sin_actores = (dfs_unidos['n_act'] == 0).sum()
print(f"üé≠ Pel√≠culas con 0 actores: {sin_actores}")

# 3Ô∏è‚É£ Cu√°ntas pel√≠culas tienen votaci√≥n igual a 0
vot_cero = (dfs_unidos['vot_av'] == 0).sum()
print(f"‚≠ê Pel√≠culas con vot_av = 0: {vot_cero}")

# 4Ô∏è‚É£ Cu√°ntas cumplen ambas condiciones a la vez (para evitar contarlas dos veces)
ambas_condiciones = ((dfs_unidos['n_act'] == 0) & (dfs_unidos['vot_av'] == 0)).sum()
print(f"üîÅ Pel√≠culas con 0 actores Y votaci√≥n 0: {ambas_condiciones}")

# 5Ô∏è‚É£ Pel√≠culas eliminadas realmente (sin contar duplicados)
eliminadas = sin_actores + vot_cero - ambas_condiciones
print(f"üßπ Total de pel√≠culas eliminadas: {eliminadas}")

# 6Ô∏è‚É£ Total esperado tras la limpieza
esperado_final = total_original - eliminadas
print(f"üìä Total esperado tras limpieza: {esperado_final}")

# 7Ô∏è‚É£ Total real en dfs_limpio
real_final = len(dfs_limpio)
print(f"‚úÖ Total real en dfs_limpio: {real_final}")

# 8Ô∏è‚É£ Comprobaci√≥n final
if real_final == esperado_final:
    print("‚úîÔ∏è Limpieza verificada: todo cuadra.")
else:
    print("‚ö†Ô∏è Algo no cuadra: revisar condiciones.")


# 1Ô∏è‚É£ Contamos cu√°ntos t√≠tulos √∫nicos hay
titulos_unicos = dfs_limpio['title'].nunique()
print(f"üî¢ N√∫mero de t√≠tulos √∫nicos: {titulos_unicos}")

# 2Ô∏è‚É£ Contamos el total de filas (pel√≠culas)
total_peliculas = len(dfs_limpio)
print(f"üé¨ Total de pel√≠culas en dfs_limpio: {total_peliculas}")

# 3Ô∏è‚É£ Calculamos cu√°ntos t√≠tulos est√°n repetidos
titulos_repetidos = total_peliculas - titulos_unicos
print(f"‚ôªÔ∏è T√≠tulos repetidos: {titulos_repetidos}")

# 4Ô∏è‚É£ (Opcional) Mostrar los t√≠tulos duplicados y cu√°ntas veces se repiten
print("\nüìã T√≠tulos repetidos (top 10):")
repetidos = dfs_limpio['title'].value_counts()
repetidos = repetidos[repetidos > 1].head(10)
print(repetidos)


# 1Ô∏è‚É£ Obtenemos los t√≠tulos que aparecen m√°s de una vez
titulos_duplicados = dfs_limpio['title'].value_counts()
titulos_duplicados = titulos_duplicados[titulos_duplicados > 1].index.tolist()

# 2Ô∏è‚É£ Filtramos el DataFrame para mostrar solo las pel√≠culas con esos t√≠tulos repetidos
registros_duplicados = dfs_limpio[dfs_limpio['title'].isin(titulos_duplicados)]

# 3Ô∏è‚É£ Ordenamos por t√≠tulo para verlos juntos
registros_duplicados = registros_duplicados.sort_values(by='title')

# 4Ô∏è‚É£ Mostramos el resultado

pd.set_option('display.max_rows', None)  # Mostrar todas las filas si hay pocas
registros_duplicados.reset_index(drop=True, inplace=True)
registros_duplicados


# Funci√≥n que clasifica cada pel√≠cula seg√∫n el n√∫mero de actores principales
def clasificar_grupo(n):
    """
    Clasifica una pel√≠cula en uno de tres grupos seg√∫n cu√°ntos actores principales tiene.
    """
    if n <= 2:
        return '1-2'     # Grupo con 1 o 2 actores
    elif n <= 4:
        return '3-4'     # Grupo con 3 o 4 actores
    else:
        return '5+'      # Grupo con 5 o m√°s actores

# Aplicamos la funci√≥n a la columna 'n_act' y creamos la nueva columna 'g_act'
dfs_limpio['g_act'] = dfs_limpio['n_act'].apply(clasificar_grupo)

# Mostramos una vista previa para verificar
print("‚úÖ Grupos creados y asignados correctamente:")
dfs_limpio.head(25)



# Agrupamos las pel√≠culas por el grupo de actores 'g_act'
# y calculamos la media de valoraci√≥n 'vot_av' en cada grupo
media_por_grupo = dfs_limpio.groupby('g_act')['vot_av'].mean().reset_index()

# Ordenamos los grupos en el orden deseado: '1-2', '3-4', '5+'
orden_grupos = ['1-2', '3-4', '5+']
media_por_grupo['g_act'] = pd.Categorical(media_por_grupo['g_act'], categories=orden_grupos, ordered=True)
media_por_grupo = media_por_grupo.sort_values('g_act')

# Mostramos el resultado
print("üìä Valoraci√≥n media por grupo de actores:")
media_por_grupo


# Definimos los datos
grupos = media_por_grupo['g_act']
medias = media_por_grupo['vot_av']

# Paleta de azules claros a oscuros
colores = ['#ADD8E6', '#4682B4', '#0B3D91']

# Crear gr√°fico de barras con colores personalizados
plt.figure(figsize=(8, 5))
plt.bar(grupos, medias, color=colores, width=0.6)

# A√±adir etiquetas y t√≠tulo con separaci√≥n mejorada
plt.title("Valoraci√≥n media seg√∫n n√∫mero de actores principales", pad=15)
plt.xlabel("N¬∫ de actores principales", labelpad=15)
plt.ylabel("Valoraci√≥n IMDB", labelpad=10)

# Mostrar valores sobre cada barra
for i, valor in enumerate(medias):
    plt.text(i, valor + 0.03, f"{valor:.2f}", ha='center', fontsize=10)

plt.tight_layout()

# Guardamos el gr√°fico

guardar_grafico()




# Ajustamos el tama√±o de la figura
plt.figure(figsize=(8, 5))

# Creamos el boxplot con seaborn
sns.boxplot(
    data=dfs_limpio,
    x='g_act',        # Clasificaci√≥n: 'seria' o 'ligera'
    y='vot_av',         # Valoraci√≥n media
    palette='pastel'          # Colores suaves (opcional)
)

# A√±adimos t√≠tulo y etiquetas
plt.title('Distribuci√≥n de valoraciones por tipo de pel√≠cula (boxplot)')
plt.xlabel('Tipo de pel√≠cula')
plt.ylabel('Valoraci√≥n media (vote_average)')

# Guardamos el gr√°fico

guardar_grafico()